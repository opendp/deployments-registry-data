description: |
  Description of a differential privacy deployment.
  All strings will be rendered as markdown with latex in the frontend.
  The `tiers` in this schema are suggested, but except for the fields
  marked as `required`, there are not rigorous requirements.

  This schema is based on ongoing research by Elena Ghazi, Priyanka Nanayakkara, and Salil Vadhan.
type: object
additionalProperties: False
required:
  - status
  - registry_authors
  - tier
  - deployment
properties:
  status:
    description: Approval status of this record.
    type: string
    enum:
      - "Converted" # Automatically converted from earlier collection of "cases".
      - "Draft" # Newly authored record.
      - "Pending" # Waiting for review by the board.
      - "Changes Required" # Board requires changes.
      - "Approved" # Yay!
      - "Approved (Update Requested)" # Small updates requested, but still can be displayed as "Approved".
      - "Approved (Pending)" # Small updates made.
  registry_authors:
    description: The author(s) of this record. This refers to who filled out the entry, which might be different from who made the deployment.
    type: array
    items:
      type: string
    minItems: 1
  tier:
    description: The completeness of the description. For higher tiers, more fields are filled in, but this is guidance, rather than a requirement.
    type: integer
    enum:
      - 1
      - 2
      - 3
  deployment:
    type: object
    additionalProperties: False
    required:
      - name
      - data_curator
      - description
      - intended_use
      - data_product_type
      - data_product_region
      - publication_date
    properties:
      name:
        tier: 1
        description: The name of the data product
        type: string
      data_curator:
        tier: 1
        description: The name of the entity publishing the data product.
        type: string
      description:
        tier: 1
        description: Brief description of the data product.
        type: string
      intended_use:
        tier: 1
        description: Intended use(s) of the data product.
        type: string
      data_product_type:
        tier: 1
        description: Type of data product. This enumeration will grow over time with more examples.
        type: string
        enum:
          - Summary statistics
          - Machine learning model
          - Dataset
          # Add to this list as needed.
      publication_date:
        tier: 1
        description: When the data product was published, in YYYY-MM-DD format. Day and month can be set to "01" if unknown. In cases of many releases, the publication date can be expressed as the date of first publication.
        type: string
        format: date
      data_product_region:
        tier: 1
        description: Free text. What region does the data describe, and/or, what region's laws apply to this data product.
        type: string
      data_product_sector:
        tier: 1
        description: The industry or domain described by the data product.
        type: string
        enum:
          - Technology
          - Healthcare
          - Education
          - Government
          # Add to this list as needed.

      # Tiers 2 and 3
      dp_flavor:
        type: object
        additionalProperties: False
        required:
          - name
          - data_domain
          - unprotected_quantities
        properties:
          name:
            tier: 2
            description: |
              The name of the DP flavor used, like "Pure DP", or "Approximate DP".

              If a commonly-known flavor was not used, it can be expressed as "Custom".

              If "Custom" is used, then specify the `input_metric`, `bound_on_input_distance`, `output_measure`, `bound_on_output_distance`
            type: string
            enum:
              - Pure DP
              - Approximate DP
              - Zero-concentrated DP
              - Renyi DP
              - Custom
          input_metric:
            description: Function that computes the distance between between any two datasets in the data domain (based partly on HoDP, pg 55).
            type: string
          bound_on_input_distance:
            description: Maximum distance, computed by the input metric, between any two datasets in the data domain; pairs of datasets whose distance is within this bound are called “adjacent datasets”.
            type: string
          output_measure:
            description: Function that computes the distance between probability distributions of the differentially private mechanism applied to datasets in the data domain.
            type: string
          bound_on_output_distance:
            description: Maximum distance, computed by the output metric, between probability distributions of the differentially private mechanism applied to adjacent datasets.
            type: string
          data_domain:
            tier: 3
            description: Actual, potential, or counterfactual datasets eligible for protection.
            type: string
          unprotected_quantities:
            tier: 3
            description: Any quantities in the data product that are unprotected by DP (e.g., statistics computed over a dataset that are released in the clear, without DP noise, and sometimes called “invariants”).
            type: string
      privacy_loss:
        type: object
        additionalProperties: False
        required:
          - privacy_unit
          - privacy_parameters
        properties:
          privacy_unit:
            tier: 2
            description: The entity whose data changes under adjacent datasets (see above), like a user or a user’s contribution (among multiple) (based partly on Bailie et al. 2025). High-level description of the granularity of protection (e.g., user level; user-day).
            type: string
          privacy_unit_description:
            tier: 3
            description: A precise specification of what constitutes adjacent datasets (e.g., in terms of your dataset schema. Function that computes the distance between between any two datasets in the data domain (based partly on HoDP, pg 55) Maximum distance, computed by the input metric, between any two datasets in the data domain; pairs of datasets whose distance is within this bound are called “adjacent datasets”.
            type: string
          privacy_parameters:
            tier: 2
            description: Intensity of protection, as characterized by values set for parameters like epsilon, delta, or rho. Which parameters are specified will vary according to the DP flavor.
            type: object
            additionalProperties: False
            properties:
              epsilon:
                type: number
              rho:
                type: number
              delta:
                type: number
          privacy_parameters_description:
            tier: 3
            description: More detail on the parameters, if necessary.
      model:
        type: object
        additionalProperties: False
        required:
          - model_name
        properties:
          model_name:
            tier: 2
            description: Name of the deployment model. “The models differ based on how much trust individuals in the data have in a central authority data system.” (HoDP, pg 34)
            type: string
            enum:
              - Local
              - Central
              - Shuffle
              - Federated
              - Varies # Present in converted records
          model_name_description:
            type: string
          actors:
            tier: 3
            description: Who are the relevant actors in the deployment? This includes anyone who may see the data product, even partially, and including adversaries. What are their trust assumptions and what is the rationale for these trust assumptions?
            type: string
          is_many_release:
            tier: 2
            description: |
               If `False`, the data product is comprised of one relase and it is published once.

               If `True`, the data product is comprised of many release and there are many publications of it over time.
            type: boolean
          is_many_release_description:
            description: |
              For one-release deployments, entries should state if there are plans for future uses or publications of the data used to create the data product.

              For many-release deployments, entries should include a description of the refreshment timeframe (the amount of time after which the privacy loss budget resets), how privacy loss is managed over time, and whether a fixed amount of privacy loss is allowed before the data used to create the data product is no longer queried.
            type: string
          is_dynamic:
            tier: 2
            description: If the underlying data are dynamic, it means that new underlying data come in over time. On the other hand, if the underlying data are static, new data do not come in over time.
            type: boolean
          is_dynamic_description:
            tier: 3
            description: If more description is useful.
          is_interactive:
            tier: 2
            description: |
              Under interactive deployments, people with permission, like data analysts, can interactively query the underlying data under differential privacy. They will be returned privacy-protected query estimates.
            type: boolean
          is_interactive_description:
            tier: 3
            description: Tier 3 entries that are interactive should also describe how the privacy loss budget is apportioned to and across analysts, and whether non-collusion between analysts is assumed. Under non-interactive deployments, people cannot interactively query the underlying data. Instead, they must interact with the published data product as is.
            type: string
      accounting:
        type: object
        additionalProperties: False
        required:
          - post_processing
          - composition
        properties:
          post_processing:
            tier: 3
            description: Functions applied to the data product after being protected under DP
            type: string
          composition:
            tier: 3
            description: How privacy loss is accounted across multiple differentially private queries, like sequential or parallel composition
            type: string
      implementation:
        type: object
        additionalProperties: False
        required:
          - pre_processing_eda_hyperparameter_tuning
          - mechanisms
          - justification
        properties:
          pre_processing_eda_hyperparameter_tuning:
            tier: 3
            description: Description of any pre-processing of the data before DP protections and any exploratory data analysis conducted before DP protections, and whether privacy loss was accounted for. How were hyperparameters, like privacy loss parameters, tuned? Was privacy loss associated with this tuning accounted for?
            type: string
          mechanisms:
            tier: 3
            description: |
              - Differentially private mechanisms (i.e., algorithms) used to produce the data product, like the Laplace or Gaussian Mechanisms.
              - How the mechanisms were implemented. If via a library, which one?
              - If interactive, what measures, if any, were taken to protect against timing channel attacks?
              - What measures, if any, were taken to protect against floating point errors?
              - What measures, if any, were taken to protect against leakage due to idiosyncrasies of the computing platform?
              - What security measures are in place to protect the underlying data (i.e., the data before being processed under DP)? What access controls are in place?
              - Version of the code & github link, if available
            type: string
          justification:
            tier: 3
            description: |
              Process by which any of the above choices surrounding implementation of DP were made, and well as any rationale around these decisions. Some questions that this section may answer include, but are not limited to:

              “What were the assumptions, modelling decisions, thresholds, and subjective decisions made in determining the implementation choices above? Why is the approach a thorough test of the stated assumptions? Was the process validated and verified? If so, how?” (Dwork Kohli Mulligan 2019)
            type: string
      additional_information:
        tier: 1
        type: string
