description: |
  Description of a differential privacy deployment.
  All strings will be interpretted as markdown when rendered.
type: object
additionalProperties: False
required:
  - status
  - registry_authors
  - deployment
properties:
  status:
    description: Approval status of this record.
    type: string
    enum:
      - "Converted" # Automatically converted from earlier collection of "cases".
      - "Draft" # Newly authored record.
      - "Pending" # Waiting for review by the board.
      - "Changes Required" # Board requires changes.
      - "Approved" # Yay!
      - "Approved (Update Requested)" # Small updates requested, but still can be displayed as "Approved".
      - "Approved (Pending)" # Small updates made.
  registry_authors:
    description: The authors of this record.
    type: array
    items:
      type: string
    minItems: 1
  deployment:
    type: object
    additionalProperties: False
    required:
      - name
      - data_curator
      - intended_use
      - data_product_type
      - data_product_region
      - data_product_description
      - publication_date
    properties:
      # Tier 1
      data_curator:
        description: The name of the entity publishing the data product.
        type: string
      description:
        description: Brief description of the data product.
        type: string
      intended_use:
        description: Intended use(s) of the data product.
        type: string
      publication_date:
        description: When the data product was published, in YYYY-MM-DD format. Day and month can be set to "01" if unknown. In cases of continual release, the publication date can be expressed as the date of first publication.
        type: string
        format: date
      data_product_region:
        description: Free text. What region does the data describe, and/or, what region's laws apply to this data product.
        type: string
      additional_information_urls:
        # Required, but may be empty. Requiring a list makes the display logic a little simpler.
        type: array
        items:
          type: string
          format: url

      # Tiers 2 and 3
      dp_flavor:
        type: object
        additionalProperties: False
        required:
          - name
          - data_domain
          - unprotected_quantities
        properties:
          name:
            description: |
              The name of the DP flavor used, like "Pure DP", or "Approximate DP".

              If a commonly-known flavor was not used, it can be expressed as "other".

              If "other" is used, then specify the `input_metric`, `bound_on_input_distance`, `output_measure`, `bound_on_output_distance`
            type: string
            enum:
              - pure DP
              - approximate DP
              - zero concentrated DP
              - Renyi DP
              - other
          input_metric:
            description: Function that computes the distance between between any two datasets in the data domain (based partly on HoDP, pg 55)
            type: string
          bound_on_input_distance:
            description: Maximum distance, computed by the input metric, between any two datasets in the data domain; pairs of datasets whose distance is within this bound are called “adjacent datasets”.
            type: string
          output_measure:
            description: Function that computes the distance between probability distributions of the differentially private mechanism applied to datasets in the data domain.
            type: string
          bound_on_output_distance:
            description: Maximum distance, computed by the output metric, between probability distributions of the differentially private mechanism applied to adjacent datasets.
            type: string
          data_domain:
            description: Actual, potential, or counterfactual datasets eligible for protection
            type: string
          unprotected_quantities:
            description: Any quantities in the data product that are unprotected by DP (e.g., statistics computed over a dataset that are released in the clear, i.e., without DP noise. Sometimes these are called “invariants.”)
            type: string
      privacy_loss:
        type: object
        additionalProperties: False
        required:
          - privacy_unit
          - privacy_parameters
        properties:
          privacy_unit:
            description: The entity whose data changes under adjacent datasets (see above), like a user or a user’s contribution (among multiple) (based partly on Bailie et al. 2025). High-level description of the granularity of protection (e.g., user level; user-day).
            type: string
          privacy_unit_description:
            description: A precise specification of what constitutes adjacent datasets (e.g., in terms of your dataset schema. Function that computes the distance between between any two datasets in the data domain (based partly on HoDP, pg 55) Maximum distance, computed by the input metric, between any two datasets in the data domain; pairs of datasets whose distance is within this bound are called “adjacent datasets”.
            type: string
          privacy_parameters:
            description: Intensity of protection, as characterized by values set for parameters like epsilon, delta, or rho. Which parameters are specified will vary according to the DP flavor.
            type: object
            additionalProperties: False
            properties:
              epsilon:
                type: number
              rho:
                type: number
              delta:
                type: number
          privacy_parameters_description:
            description: More detail on the parameters, if necessary.
      model:
        type: object
        additionalProperties: False
        required:
          - model_name
          - release_type
          - interactivity
        properties:
          model_name:
            description: Name of the deployment model. “The models differ based on how much trust individuals in the data have in a central authority data system.” (HoDP, pg 34)
            type: string
            enum:
              - local
              - central
              - shuffle
              - federated
              - not specified # TODO: Present in converted records. Find value, or make field optional?
              - varies # TODO: Present in converted records. Make this a list, instead of a single value?
          actors:
            description: Who are the relevant actors in the deployment? This includes anyone who may see the data product, even partially, and including adversaries. What are their trust assumptions and what is the rationale for these trust assumptions?
            type: string
          model_type_description:
            # TODO: Description for this field?
            type: string
          one_or_many_shot:
            description: |
               If the data product is `one-shot`, it is published once.

               If the data product is `many-shot`, there are many publications of it over time.
            type: string
            enum:
              - one-shot
              - many-shot
          one_or_many_shot_description:
            description: |
              For `one-shot` deployments, entries should state if there are plans for future uses or publications of the data used to create the data product.

              For `many-shot` deployments, entries should include a description of the refreshment timeframe (the amount of time after which the privacy loss budget resets), how privacy loss is managed over time, and whether a fixed amount of privacy loss is allowed before the data used to create the data product is no longer queried.
            type: string
          dynamic_or_static:
            description: If the underlying data are dynamic, it means that new underlying data come in over time. On the other hand, if the underlying data are static, new data do not come in over time.
            enum:
              - dynamic
              - static
          dynamic_or_static_description:
            description: If more description is useful
          interactive_or_noninteractive:
            description: |
              Under interactive deployments, people with permission, like data analysts, can interactively query the underlying data under differential privacy. They will be returned privacy-protected query estimates.
            type: string
            enum:
              - interactive
              - non-interactive
          interactive_or_noninteractive_description:
            description: Tier 3 entries that are interactive should also describe how the privacy loss budget is apportioned to and across analysts, and whether non-collusion between analysts is assumed. Under non-interactive deployments, people cannot interactively query the underlying data. Instead, they must interact with the published data product as is.
            type: string
      accounting:
        type: object
        additionalProperties: False
        required:
          - post_processing
          - composition
        properties:
          post_processing:
            description: Functions applied to the data product after being protected under DP
            type: string
          composition:
            description: How privacy loss is accounted across multiple differentially private queries, like sequential or parallel composition
            type: string
      implementation:
        type: object
        additionalProperties: False
        required:
          - pre_processing_eda_hyperparameter_tuning
          - mechanisms
          - justification
        properties:
          pre_processing_eda_hyperparameter_tuning:
            description: Description of any pre-processing of the data before DP protections and any exploratory data analysis conducted before DP protections, and whether privacy loss was accounted for. How were hyperparameters, like privacy loss parameters, tuned? Was privacy loss associated with this tuning accounted for?
            type: string
          mechanisms:
            description: |
              - Differentially private mechanisms (i.e., algorithms) used to produce the data product, like the Laplace or Gaussian Mechanisms.
              - How the mechanisms were implemented. If via a library, which one?
              - If interactive, what measures, if any, were taken to protect against timing channel attacks?
              - What measures, if any, were taken to protect against floating point errors?
              - What measures, if any, were taken to protect against leakage due to idiosyncrasies of the computing platform?
              - What security measures are in place to protect the underlying data (i.e., the data before being processed under DP)? What access controls are in place?
              - Version of the code & github link, if available
            type: string
          justification:
            description: |
              Process by which any of the above choices surrounding implementation of DP were made, and well as any rationale around these decisions. Some questions that this section may answer include, but are not limited to:

              “What were the assumptions, modelling decisions, thresholds, and subjective decisions made in determining the implementation choices above? Why is the approach a thorough test of the stated assumptions? Was the process validated and verified? If so, how?” (Expose your epsilons)
            type: string
